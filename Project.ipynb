{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ine-divider](https://user-images.githubusercontent.com/7065401/92672068-398e8080-f2ee-11ea-82d6-ad53f7feb5c0.png)\n",
    "<hr>\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "## Categorical features and dirty cats\n",
    "\n",
    "In this project, you will be working with dirty cats again to practice all the techniques you learned on previous lessons.  \n",
    "\n",
    "**Remember**: it's important to always learn from your training data and transform your test data.  Let's gain some practice applying feature engineering to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Bassoon</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Piano</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nom_0      nom_1    nom_2    nom_3     nom_4  ord_0        ord_1  \\\n",
       "0  Green   Triangle    Snake  Finland   Bassoon      2  Grandmaster   \n",
       "1  Green  Trapezoid  Hamster   Russia     Piano      1  Grandmaster   \n",
       "2   Blue  Trapezoid     Lion   Russia  Theremin      1       Expert   \n",
       "3    Red  Trapezoid    Snake   Canada      Oboe      1  Grandmaster   \n",
       "4    Red  Trapezoid     Lion   Canada      Oboe      1  Grandmaster   \n",
       "\n",
       "         ord_2  \n",
       "0         Cold  \n",
       "1          Hot  \n",
       "2     Lava Hot  \n",
       "3  Boiling Hot  \n",
       "4     Freezing  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in dirty_cats.csv\n",
    "df_dirty = pd.read_csv('datasets/dirty_cats.csv')\n",
    "\n",
    "df_dirty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "## How do we get dummies from our train set and apply them to our test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with our nom_0 column again\n",
    "# Get dummies for nom_0\n",
    "df_dummies = pd.get_dummies(df_dirty['nom_0'], drop_first=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BULE', 'Blue', 'Bule', 'GEREN', 'GREEN', 'Geren', 'Green', 'RED',\n",
       "       'Rde', 'Red', 'blue', 'green', 'red'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the dummy colum\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### nom_0 has 3 categories: Green, Blue and Red\n",
    "But, the dummies (because we dropped a column) only has 2 of the 3.\n",
    "\n",
    "> How do we make sure our test dummies has the same 2 out of 3 columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "# There's no target in this toy dataset.  We can just split the data randomly\n",
    "# Select 80% of the data randomly for train\n",
    "msk = np.random.rand(len(df_dirty)) < 0.8\n",
    "# Pull the train data out\n",
    "df_train = df_dirty[msk].copy()\n",
    "# Pull the test data out\n",
    "df_test = df_dirty[~msk].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Why Split Data?\\nLearning Transformations on Training Data Only\\nWhy is it necessary?\\n\\n    In real-world machine learning, your model learns patterns from the training data and is evaluated on unseen test data.\\n    Any preprocessing steps (like dummy encoding) must also mimic this principle:\\n        Learn how to transform data only on the training data.\\n        Apply those learned transformations to the test data.\\n        \\nWhat happens if you use the entire dataset (no split)?\\n\\nIf you use the entire dataset for learning transformations (e.g., creating dummy variables), information from the test set can \"leak\" into the training process. This is called data leakage.\\nIt gives the model access to information it wouldn\\'t normally have in a real-world scenario, leading to overly optimistic performance metrics.\\nExample of Data Leakage:\\n\\nImagine your nom_0 column has the following categories:\\nTraining Data: [\\'Green\\', \\'Blue\\', \\'Red\\']\\nTest Data: [\\'Green\\', \\'Blue\\', \\'Yellow\\']\\nIf you include the test data while creating dummies, the model will learn about the Yellow category from the test data. In reality, the model should treat Yellow as unseen during evaluation.\\nKey Rule: Split the data into training and testing to ensure the test set remains unseen until evaluation.\\n\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. Why Split Data?\n",
    "Learning Transformations on Training Data Only\n",
    "Why is it necessary?\n",
    "\n",
    "    In real-world machine learning, your model learns patterns from the training data and is evaluated on unseen test data.\n",
    "    Any preprocessing steps (like dummy encoding) must also mimic this principle:\n",
    "        Learn how to transform data only on the training data.\n",
    "        Apply those learned transformations to the test data.\n",
    "        \n",
    "What happens if you use the entire dataset (no split)?\n",
    "\n",
    "If you use the entire dataset for learning transformations (e.g., creating dummy variables), information from the test set can \"leak\" into the training process. This is called data leakage.\n",
    "It gives the model access to information it wouldn't normally have in a real-world scenario, leading to overly optimistic performance metrics.\n",
    "Example of Data Leakage:\n",
    "\n",
    "Imagine your nom_0 column has the following categories:\n",
    "Training Data: ['Green', 'Blue', 'Red']\n",
    "Test Data: ['Green', 'Blue', 'Yellow']\n",
    "If you include the test data while creating dummies, the model will learn about the Yellow category from the test data. In reality, the model should treat Yellow as unseen during evaluation.\n",
    "Key Rule: Split the data into training and testing to ensure the test set remains unseen until evaluation.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BULE', 'Blue', 'Bule', 'GREEN', 'Geren', 'Green', 'RED', 'Rde', 'Red',\n",
       "       'blue', 'green', 'red'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn our dummy columns from our train data\n",
    "# Use pd.get_dummies to get dummy columns for train data\n",
    "df_train_dummies = pd.get_dummies(df_train['nom_0'], drop_first=True).astype(int)\n",
    "\n",
    "# Save the columns from the dummy data frame as a list\n",
    "train_dummies = df_train_dummies.columns\n",
    "train_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "## Checking dummy columns\n",
    "\n",
    "There are 2 things you need to check for when applying what you learned about dummies in train to the test data\n",
    "1. What dummy columns (categories) are missing from test that were in train?\n",
    "    - We'll add these and fill the values with 0\n",
    "2. What dummy columns (categories) are in test that were not in train?\n",
    "    - We'll drop these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use set operations to get the sets we need to answer the questions above\n",
    "# Make the train_dummies column list into a set\n",
    "train_set = set(train_dummies)\n",
    "# Get the unique categories from test and create a set\n",
    "test_set = set(df_test.nom_0.unique().tolist())\n",
    "# cols to add exist in train, but not in test\n",
    "cols_to_add = train_set.difference(test_set)\n",
    "# cols to remove exist in test but not in train\n",
    "cols_to_remove = test_set.difference(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BULE', 'Blue', 'Geren', 'RED', 'Red', 'Bule', 'GREEN', 'blue', 'red', 'green', 'Green', 'Rde'}\n",
      "{'Blue', 'BLUE', 'GEREN', 'Red', 'blue', 'red', 'Green', 'Rde'}\n",
      "{'BULE', 'Geren', 'RED', 'Bule', 'GREEN', 'green'}\n",
      "{'GEREN', 'BLUE'}\n"
     ]
    }
   ],
   "source": [
    "print(train_set)\n",
    "print(test_set)\n",
    "print(cols_to_add)\n",
    "print(cols_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "## Now that we know what columns to look for, let's apply what we know to our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the test set (we want to start with all of the columns)\n",
    "df_test_onehot = pd.get_dummies(df_test['nom_0']).astype(int)\n",
    "# Add any cols that are missing -> fill values with 0\n",
    "for col in cols_to_add:\n",
    "    df_test_onehot[col] = 0\n",
    "# Remove any cols that weren't in train\n",
    "df_test_dummies = df_test_onehot.drop(cols_to_remove,axis=1)\n",
    "\n",
    "# Check that the width (number of columns) of train dummies and test dummies match\n",
    "print(len(df_test_dummies.columns) == len(df_train_dummies.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncreates a preliminary set of dummy variables for the test set, but it may include extra categories or miss some that exist in the training set.\\n\\nPurpose: Handle columns (categories) that are in the training set but missing from the test set.\\nHow:\\ncols_to_add contains the names of dummy columns present in the training set but absent from the test set.\\nFor each missing column, a new column is added to df_test_onehot with all values set to 0.\\nWhy: Ensures that the test set has all the dummy columns required by the model.\\n\\nPurpose: Handle columns (categories) that are in the test set but not in the training set.\\nHow:\\ncols_to_remove contains the names of dummy columns present in the test set but not in the training set.\\nThese columns are dropped from df_test_onehot.\\nWhy: Ensures that only the dummy columns learned during training are present in the test set.\\n\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "creates a preliminary set of dummy variables for the test set, but it may include extra categories or miss some that exist in the training set.\n",
    "\n",
    "Purpose: Handle columns (categories) that are in the training set but missing from the test set.\n",
    "How:\n",
    "cols_to_add contains the names of dummy columns present in the training set but absent from the test set.\n",
    "For each missing column, a new column is added to df_test_onehot with all values set to 0.\n",
    "Why: Ensures that the test set has all the dummy columns required by the model.\n",
    "\n",
    "Purpose: Handle columns (categories) that are in the test set but not in the training set.\n",
    "How:\n",
    "cols_to_remove contains the names of dummy columns present in the test set but not in the training set.\n",
    "These columns are dropped from df_test_onehot.\n",
    "Why: Ensures that only the dummy columns learned during training are present in the test set.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "## One final thing\n",
    "\n",
    "When the numbers of columns match, you have one more thing you need to check --> that the columns are in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BULE <===> BULE\n",
      "Blue <===> Blue\n",
      "Bule <===> Bule\n",
      "GEREN <===> GEREN\n",
      "GREEN <===> GREEN\n",
      "Geren <===> Geren\n",
      "Green <===> Green\n",
      "RED <===> RED\n",
      "Rde <===> Rde\n",
      "Red <===> Red\n",
      "blue <===> blue\n",
      "green <===> green\n",
      "red <===> red\n"
     ]
    }
   ],
   "source": [
    "# We already has an ordered list of columns from train in train_dummies\n",
    "# Let's apply that column order to test dummies\n",
    "df_test_dummies = df_test_dummies[train_dummies]\n",
    "\n",
    "# Check that the columns in train and test match\n",
    "for train_col,test_col in zip(df_train_dummies.columns,df_test_dummies.columns):\n",
    "    print(train_col,'<===>',test_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\ntrain_dummies is the ordered list of dummy columns from the training data.\\nThe test DataFrame (df_test_dummies) is reindexed to match this order.\\nWhy: Ensures that the test set dummy columns are aligned in the same order as the training set.\\n\\nOrder matters in machine learning:\\nModels treat input features as arrays. If the order of the columns differs between training and test sets, the model could receive incorrect inputs, leading to unpredictable behavior.\\nThis step ensures both the structure and order of the columns are consistent.\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "train_dummies is the ordered list of dummy columns from the training data.\n",
    "The test DataFrame (df_test_dummies) is reindexed to match this order.\n",
    "Why: Ensures that the test set dummy columns are aligned in the same order as the training set.\n",
    "\n",
    "Order matters in machine learning:\n",
    "Models treat input features as arrays. If the order of the columns differs between training and test sets, the model could receive incorrect inputs, leading to unpredictable behavior.\n",
    "This step ensures both the structure and order of the columns are consistent.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "## Incongruent data labeling\n",
    "\n",
    "Looks like we have some incongruent data labeling in this data.\n",
    "\n",
    "> Go back and fix the labeling then redo the dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nom_0\n",
       "Green    101840\n",
       "Blue      76917\n",
       "Red       61090\n",
       "blue          4\n",
       "Rde           4\n",
       "RED           3\n",
       "GREEN         3\n",
       "green         3\n",
       "Bule          2\n",
       "red           2\n",
       "Geren         2\n",
       "BULE          2\n",
       "GEREN         2\n",
       "BLUE          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique categories in nom_0 using value_counts()\n",
    "df_train['nom_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like making case uniform will solve part of the problem\n",
    "# Apply .lower() to train and test\n",
    "df_train['nom_0'] = df_train['nom_0'].apply(lambda x: x.lower())\n",
    "df_test['nom_0'] = df_test['nom_0'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nom_0\n",
       "green    101846\n",
       "blue      76922\n",
       "red       61095\n",
       "bule          4\n",
       "rde           4\n",
       "geren         4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have another look at the train categories\n",
    "df_train['nom_0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping using train data only to correct spelling\n",
    "nom_0_map = {'bule':'blue','rde':'red','geren':'green','blue':'blue','red':'red','green':'green'}\n",
    "# Use .map to apply the mapping to train data\n",
    "df_train['nom_0_mapped'] = df_train['nom_0'].map(nom_0_map)\n",
    "# Use .map to apply the mapping to test data\n",
    "df_test['nom_0_mapped'] = df_test['nom_0'].map(nom_0_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nom_0_mapped\n",
       "green    101850\n",
       "blue      76926\n",
       "red       61099\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check categories in train\n",
    "df_train['nom_0_mapped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've cleaned up our labeling, let's make our dummy columns again\n",
    "# Learn our dummy columns from our train data\n",
    "df_train_dummies = pd.get_dummies(df_train['nom_0_mapped'], drop_first=True).astype(int)\n",
    "# keep the dummy cols for use on test data\n",
    "train_dummies = df_train_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we don't know that our test categories match our train categories \n",
    "# (this should always be your assumption)\n",
    "# Get the cols to check\n",
    "# Let's use set operations to get the sets we need to answer the questions above\n",
    "# Make the train_dummies column list into a set\n",
    "train_set = set(train_dummies)\n",
    "# Get the unique categories from test and create a set\n",
    "test_set = set(df_test.nom_0_mapped.unique().tolist())\n",
    "# cols to add exist in train, but not in test\n",
    "cols_to_add = train_set.difference(test_set)\n",
    "# cols to remove exist in test but not in train\n",
    "cols_to_remove = test_set.difference(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the test set (we want to start with all of the columns)\n",
    "df_test_onehot = pd.get_dummies(df_test.nom_0_mapped).astype(int)\n",
    "# Add any cols that are missing\n",
    "for col in cols_to_add:\n",
    "    df_test_onehot[col] = 0\n",
    "# Remove any cols that weren't in train\n",
    "df_test_dummies = df_test_onehot.drop(cols_to_remove,axis=1)\n",
    "\n",
    "# Check that the width of train dummies and test dummies match\n",
    "df_train_dummies.shape[1],df_test_dummies.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   green  red\n",
       "0      1    0\n",
       "1      1    0\n",
       "2      0    0\n",
       "3      0    1\n",
       "5      0    0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the train data\n",
    "df_train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    green  red\n",
       "4       0    1\n",
       "20      0    0\n",
       "22      0    0\n",
       "25      1    0\n",
       "27      0    1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the test data\n",
    "df_test_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nWhy Encoding Was Done First\\nThe notebook might have gone straight to dummy encoding first for the following reasons:\\n\\nWorkflow Demonstration:\\n\\nOften, tutorials and notebooks are structured to show the standard steps (e.g., splitting, encoding, aligning columns) without anticipating data issues up front.\\nEncoding first allows the notebook to introduce the dummy variable creation process as part of a typical workflow.\\nReveal Problems Visually:\\n\\nWhile value_counts() could reveal inconsistent labels in the raw data, the issues might be more obvious when seen in the dummy columns.\\nFor example:\\nvalue_counts() could show Green and green separately, but creating dummy variables highlights that they create redundant columns, which has a more direct impact on machine learning models.\\nEducational Intent:\\n\\nEncoding first emphasizes why clean, consistent data is critical for preprocessing. Spotting the problem during encoding makes it clear how data inconsistencies can directly affect feature engineering.\\n\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Why Encoding Was Done First\n",
    "The notebook might have gone straight to dummy encoding first for the following reasons:\n",
    "\n",
    "Workflow Demonstration:\n",
    "\n",
    "Often, tutorials and notebooks are structured to show the standard steps (e.g., splitting, encoding, aligning columns) without anticipating data issues up front.\n",
    "Encoding first allows the notebook to introduce the dummy variable creation process as part of a typical workflow.\n",
    "Reveal Problems Visually:\n",
    "\n",
    "While value_counts() could reveal inconsistent labels in the raw data, the issues might be more obvious when seen in the dummy columns.\n",
    "For example:\n",
    "value_counts() could show Green and green separately, but creating dummy variables highlights that they create redundant columns, which has a more direct impact on machine learning models.\n",
    "Educational Intent:\n",
    "\n",
    "Encoding first emphasizes why clean, consistent data is critical for preprocessing. Spotting the problem during encoding makes it clear how data inconsistencies can directly affect feature engineering.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "## They match!\n",
    "\n",
    "You've successfully cleaned up labeling and created matching dummy columns for train and test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;\">\n",
    "<img src=\"https://user-images.githubusercontent.com/7065401/98729912-57be3e80-237a-11eb-80e4-233ac344b391.png\"></img>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
